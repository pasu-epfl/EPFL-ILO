{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NDC analysis.** Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Country NDCs Filepath.\n",
    "EPFL_ILO = \"/Users/atoure/Desktop/PASU/EPFL-ILO/\"\n",
    "ndcs_updated = EPFL_ILO + \"/NDC submissions/NDCs_1207\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of note, Mali and Nigeria's updated NDC submissions are not searchable. Mali's updated NDC contains pictures that, unlike other NDC submissions that contained pictures, were not able to be converted to text using OCR. Nigeria's updated NDC is highlighteable but non-searchable, probably due to non-standard font encoding. As a result, these two NDCs will not show results for the keyword search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_decent_work = ['decent work', 'decent job', 'decent jobs', 'good job', 'good jobs',\n",
    "                  'quality job', 'quality jobs']\n",
    "\n",
    "kw_green_jobs = ['green job', 'green jobs']\n",
    "\n",
    "kw_employment = ['job', 'jobs', 'employment', 'livelihood', 'employment loss', 'job loss', 'job losses']\n",
    "\n",
    "\n",
    "kw_justtransition = ['just transition', 'just energy transition', \n",
    "                     'fair transition', 'inclusive transition'] \n",
    "\n",
    "kw_social_inclusion = ['social inclusion', 'social justice', 'social equity', 'non-discrimination',\n",
    "                       'equal access opportunities', 'equal access opportunity', 'intersectionalities',\n",
    "                       'intersectionality', 'discrimination', 'equitable distribution', 'equitable outcome']\n",
    "\n",
    "kw_organizations = [\"employers' organizations\", 'employers organizations', 'business membership organizations',\n",
    "                    \"workers' organizations\", \"workers organizations\", 'trade unions', 'business organizations',\n",
    "                    'business associations', 'trade associations', 'employers associations',  \"workers associations\",\n",
    "                    'industry group', 'representative of workers', 'representatives of employers', 'workers unions', \n",
    "                    'industry group', 'representative of workers', 'representatives of employers', 'workers unions'\n",
    "                    'workers representatives', \"employers’ representatives\", \"workers’ associations\"]\n",
    "\n",
    " \n",
    "kw_stakeholders_engagement = ['stakeholders engagement', 'public engagement', 'stakeholder consultation', 'public consultation',\n",
    "                            'public participation', 'citizen participation', 'stakeholder involvement', 'involvement of stakeholders', 'involved stakeholders',\n",
    "                            'consultative process', 'civil society consultation', 'civil society participation', 'participation of actors',\n",
    "                            'participation of citizens']\n",
    " \n",
    "kw_ILO = ['ilo', 'international labor organization', 'international labour organization', 'international labour organisation', \n",
    "          'international labor organisation', 'international labour office']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction: Allowing for more whitespace characters (spaces, tabs, or newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keywords_in_pdf_corrected(pdf_file, keywords):\n",
    "    results = []\n",
    "    text = extract_text(pdf_file).lower()\n",
    "\n",
    "    for keyword in keywords:\n",
    "        # Modify the pattern to allow for any whitespace (including line breaks) between words\n",
    "        pattern = r'\\b' + r'\\s+'.join(map(re.escape, keyword.lower().split())) + r'\\b'\n",
    "        matches = re.finditer(pattern, text)\n",
    "        pages_with_keyword = []  # set()\n",
    "        total_words_found = 0\n",
    "        for match in matches:\n",
    "            page_number = text.count('\\f', 0, match.start()) + 1\n",
    "            pages_with_keyword.append(page_number)  # add(page_number)\n",
    "            total_words_found += 1\n",
    "\n",
    "        if pages_with_keyword:\n",
    "            results.append({\n",
    "                'PDF Name': os.path.basename(pdf_file),\n",
    "                'Keyword': keyword,\n",
    "                'Page Numbers': ', '.join(str(page_number) for page_number in sorted(pages_with_keyword)),\n",
    "                'Total Words Found': total_words_found\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PDF Name': 'Palestine.pdf',\n",
       "  'Keyword': 'just transition',\n",
       "  'Page Numbers': '30',\n",
       "  'Total Words Found': 1}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_keywords_in_pdf_corrected(ndcs_updated+'/Palestine.pdf', kw_justtransition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword search function\n",
    "\n",
    "This function will search through the all the Nationally Determined Contributions in the specified folder, and will return, for each country, which keywords were found, how many times, and the page at which each word appears. Only whole matches are counted, so if a keyword appears within another word in the document, it will not be counted.\n",
    "\n",
    "The code is based on code based on Dan Luca Fulger's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_keywords_in_pdf(pdf_file, keywords):\n",
    "    results = []\n",
    "    text = extract_text(pdf_file).lower()\n",
    "\n",
    "    for keyword in keywords:\n",
    "        pattern = r'\\b{}\\b'.format(re.escape(keyword.lower()))\n",
    "        matches = re.finditer(pattern, text)\n",
    "        pages_with_keyword = [] # set()\n",
    "        total_words_found = 0\n",
    "        for match in matches:\n",
    "            page_number = text.count('\\f', 0, match.start()) + 1\n",
    "            pages_with_keyword.append(page_number) # add(page_number)\n",
    "            total_words_found += 1\n",
    "\n",
    "        if pages_with_keyword:\n",
    "            results.append({\n",
    "                'PDF Name': os.path.basename(pdf_file),\n",
    "                'Keyword': keyword,\n",
    "                'Page Numbers': ', '.join(str(page_number) for page_number in sorted(pages_with_keyword)),\n",
    "                'Total Words Found': total_words_found\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def search_keywords_in_multiple_pdfs(pdf_folder, keywords):\n",
    "    pdf_files = [file for file in os.listdir(pdf_folder) if file.endswith('.pdf')]\n",
    "    all_results = []\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        results = search_keywords_in_pdf_corrected(pdf_path, keywords)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def analyze_pdfs(pdf_folder, keywords):\n",
    "    results = search_keywords_in_multiple_pdfs(pdf_folder, keywords)\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.groupby(['PDF Name', 'Keyword'], as_index=False)[['Page Numbers', 'Total Words Found']].agg({'Page Numbers': ', '.join, 'Total Words Found': 'sum'})\n",
    "        keyword_counts = df.groupby('PDF Name')['Keyword'].nunique().reset_index()\n",
    "        keyword_counts.columns = ['PDF Name', 'unique_keyword_count']\n",
    "        unique_keywords = df.groupby('PDF Name').agg({'Keyword': lambda x: list(x), \n",
    "                                                      'Page Numbers': lambda x: [pages.split(', ') for pages in x], \n",
    "                                                      'Total Words Found': 'sum'}).reset_index()\n",
    "        unique_keywords.columns = ['PDF Name', 'Unique Keywords', 'Page Numbers', 'Total Words Found']\n",
    "        final_df = pd.merge(keyword_counts, unique_keywords, on='PDF Name')\n",
    "        final_df['PDF Name'] = final_df['PDF Name'].str.replace('.pdf', '')\n",
    "        final_df.rename(columns={'PDF Name': 'Country', 'Total Words Found': 'total_words', 'Page Numbers': 'pages', 'Unique Keywords': 'unique_keywords'}, inplace=True)\n",
    "\n",
    "        all_countries = [file.replace('.pdf', '') for file in os.listdir(pdf_folder) if file.endswith('.pdf')]\n",
    "        countries_with_keywords = final_df['Country'].tolist()\n",
    "        countries_without_keywords = list(set(all_countries) - set(countries_with_keywords))\n",
    "\n",
    "        no_keywords_data = {'Country': countries_without_keywords,\n",
    "                            'unique_keyword_count': [0] * len(countries_without_keywords),\n",
    "                            'unique_keywords': [[] for _ in range(len(countries_without_keywords))],\n",
    "                            'pages': [[] for _ in range(len(countries_without_keywords))],\n",
    "                            'total_words': [0] * len(countries_without_keywords)} \n",
    "        no_keywords_df = pd.DataFrame(no_keywords_data)\n",
    "\n",
    "        final_df = pd.concat([final_df, no_keywords_df], ignore_index=True)\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel file production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: The following code takes a long time to execute (>30min). Avoid re-runs if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 /7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Argentina.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "The PDF <_io.BufferedReader name='/Users/atoure/Desktop/PASU/EPFL-ILO/NDC submissions/NDCs_1207/Ethiopia.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    }
   ],
   "source": [
    "# List of keyword lists and corresponding dataframes names\n",
    "keyword_lists = [kw_decent_work, kw_green_jobs, kw_employment, kw_stakeholders_engagement,\n",
    "                 kw_ILO, kw_justtransition, kw_social_inclusion, kw_organizations]\n",
    "dataframes_names = ['df_decent_work', 'df_green_jobs', 'df_employment', 'df_stakeholders_engagement',\n",
    "                  'df_ILO', 'df_justtransition', 'df_social_inclusion', 'df_organizations']\n",
    "\n",
    "\n",
    "for i, keywords in enumerate(keyword_lists):\n",
    "    print(i,'/7')\n",
    "    # Call the analyze_pdfs function with the current keyword list\n",
    "    dataframe = analyze_pdfs(ndcs_updated, keywords)\n",
    "    \n",
    "    # Rename the dataframe accordingly\n",
    "    globals()[dataframes_names[i]] = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_suffix = ['_green_jobs', '_employment', '_stakeholders_engagement',\n",
    "                  '_ILO', '_justtransition', '_social_inclusion', '_organizations']\n",
    "\n",
    "dataframes = [df_green_jobs, df_employment, df_stakeholders_engagement,\n",
    "                  df_ILO, df_justtransition, df_social_inclusion, df_organizations]\n",
    "\n",
    "# Start with one dataframe\n",
    "merged_df = df_decent_work.copy()\n",
    "\n",
    "# Add a suffix to each column name\n",
    "for column in merged_df.columns:\n",
    "    if column != 'Country':\n",
    "        merged_df.rename(columns={column: column + '_decent_work'}, inplace=True)\n",
    "\n",
    "# Merge dataframes using suffixes for columns\n",
    "for i in range(len(dataframes)):\n",
    "    if dataframes[i] is not None:\n",
    "        merged_df = pd.merge(merged_df, dataframes[i], on='Country', how='outer', suffixes=('',  dataframes_suffix[i]))\n",
    "        \n",
    "# Add suffix for the first merge (only added when columns perferctly match)\n",
    "for column in merged_df.columns:\n",
    "    if column != 'Country':\n",
    "        if column in df_green_jobs.columns:\n",
    "            merged_df.rename(columns={column: column + '_green_jobs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the data with relevant columns\n",
    "columns_to_include = [col for col in merged_df.columns if not col.startswith(('unique_keyword_count', 'pages'))]\n",
    "\n",
    "merged_df[columns_to_include].to_excel(EPFL_ILO + 'data/proc/keywords_search_2711.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>unique_keyword_count_decent_work</th>\n",
       "      <th>unique_keywords_decent_work</th>\n",
       "      <th>pages_decent_work</th>\n",
       "      <th>total_words_decent_work</th>\n",
       "      <th>unique_keyword_count_green_jobs</th>\n",
       "      <th>unique_keywords_green_jobs</th>\n",
       "      <th>pages_green_jobs</th>\n",
       "      <th>total_words_green_jobs</th>\n",
       "      <th>unique_keyword_count_employment</th>\n",
       "      <th>...</th>\n",
       "      <th>pages_justtransition</th>\n",
       "      <th>total_words_justtransition</th>\n",
       "      <th>unique_keyword_count_social_inclusion</th>\n",
       "      <th>unique_keywords_social_inclusion</th>\n",
       "      <th>pages_social_inclusion</th>\n",
       "      <th>total_words_social_inclusion</th>\n",
       "      <th>unique_keyword_count_organizations</th>\n",
       "      <th>unique_keywords_organizations</th>\n",
       "      <th>pages_organizations</th>\n",
       "      <th>total_words_organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[[80]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[discrimination]</td>\n",
       "      <td>[[66]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[business organizations]</td>\n",
       "      <td>[[4]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[discrimination, social inclusion, social just...</td>\n",
       "      <td>[[30], [30, 31], [32]]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Venezuela (Bolivarian Republic of)</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[discrimination, social equity, social inclusi...</td>\n",
       "      <td>[[29], [135], [34, 126], [9, 90, 118, 134, 135...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[trade unions]</td>\n",
       "      <td>[[135, 136]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>[decent work]</td>\n",
       "      <td>[[31]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[[40]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1</td>\n",
       "      <td>[decent work]</td>\n",
       "      <td>[[33]]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[green jobs]</td>\n",
       "      <td>[[17, 32, 34]]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>[[33, 33]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[intersectionality]</td>\n",
       "      <td>[[16, 16]]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Country  unique_keyword_count_decent_work  \\\n",
       "0                           Afghanistan                                 0   \n",
       "1                               Albania                                 0   \n",
       "2                               Algeria                                 0   \n",
       "3                               Andorra                                 0   \n",
       "4                                Angola                                 0   \n",
       "..                                  ...                               ...   \n",
       "190                             Vanuatu                                 0   \n",
       "191  Venezuela (Bolivarian Republic of)                                 0   \n",
       "192                            Viet Nam                                 1   \n",
       "193                              Zambia                                 0   \n",
       "194                            Zimbabwe                                 1   \n",
       "\n",
       "    unique_keywords_decent_work pages_decent_work  total_words_decent_work  \\\n",
       "0                            []                []                        0   \n",
       "1                            []                []                        0   \n",
       "2                            []                []                        0   \n",
       "3                            []                []                        0   \n",
       "4                            []                []                        0   \n",
       "..                          ...               ...                      ...   \n",
       "190                          []                []                        0   \n",
       "191                          []                []                        0   \n",
       "192               [decent work]            [[31]]                        1   \n",
       "193                          []                []                        0   \n",
       "194               [decent work]            [[33]]                        1   \n",
       "\n",
       "     unique_keyword_count_green_jobs unique_keywords_green_jobs  \\\n",
       "0                                  0                         []   \n",
       "1                                  0                         []   \n",
       "2                                  0                         []   \n",
       "3                                  0                         []   \n",
       "4                                  0                         []   \n",
       "..                               ...                        ...   \n",
       "190                                0                         []   \n",
       "191                                0                         []   \n",
       "192                                0                         []   \n",
       "193                                0                         []   \n",
       "194                                1               [green jobs]   \n",
       "\n",
       "    pages_green_jobs  total_words_green_jobs  unique_keyword_count_employment  \\\n",
       "0                 []                       0                                0   \n",
       "1                 []                       0                                3   \n",
       "2                 []                       0                                1   \n",
       "3                 []                       0                                2   \n",
       "4                 []                       0                                2   \n",
       "..               ...                     ...                              ...   \n",
       "190               []                       0                                2   \n",
       "191               []                       0                                4   \n",
       "192               []                       0                                4   \n",
       "193               []                       0                                1   \n",
       "194   [[17, 32, 34]]                       3                                5   \n",
       "\n",
       "     ... pages_justtransition total_words_justtransition  \\\n",
       "0    ...                   []                          0   \n",
       "1    ...               [[80]]                          1   \n",
       "2    ...                   []                          0   \n",
       "3    ...                   []                          0   \n",
       "4    ...                   []                          0   \n",
       "..   ...                  ...                        ...   \n",
       "190  ...                   []                          0   \n",
       "191  ...                   []                          0   \n",
       "192  ...               [[40]]                          1   \n",
       "193  ...                   []                          0   \n",
       "194  ...           [[33, 33]]                          2   \n",
       "\n",
       "     unique_keyword_count_social_inclusion  \\\n",
       "0                                        0   \n",
       "1                                        1   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "..                                     ...   \n",
       "190                                      3   \n",
       "191                                      4   \n",
       "192                                      0   \n",
       "193                                      0   \n",
       "194                                      1   \n",
       "\n",
       "                      unique_keywords_social_inclusion  \\\n",
       "0                                                   []   \n",
       "1                                     [discrimination]   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "190  [discrimination, social inclusion, social just...   \n",
       "191  [discrimination, social equity, social inclusi...   \n",
       "192                                                 []   \n",
       "193                                                 []   \n",
       "194                                [intersectionality]   \n",
       "\n",
       "                                pages_social_inclusion  \\\n",
       "0                                                   []   \n",
       "1                                               [[66]]   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "190                             [[30], [30, 31], [32]]   \n",
       "191  [[29], [135], [34, 126], [9, 90, 118, 134, 135...   \n",
       "192                                                 []   \n",
       "193                                                 []   \n",
       "194                                         [[16, 16]]   \n",
       "\n",
       "    total_words_social_inclusion  unique_keyword_count_organizations  \\\n",
       "0                              0                                   0   \n",
       "1                              1                                   0   \n",
       "2                              0                                   1   \n",
       "3                              0                                   0   \n",
       "4                              0                                   0   \n",
       "..                           ...                                 ...   \n",
       "190                            4                                   0   \n",
       "191                           11                                   1   \n",
       "192                            0                                   0   \n",
       "193                            0                                   0   \n",
       "194                            2                                   0   \n",
       "\n",
       "     unique_keywords_organizations pages_organizations  \\\n",
       "0                               []                  []   \n",
       "1                               []                  []   \n",
       "2         [business organizations]               [[4]]   \n",
       "3                               []                  []   \n",
       "4                               []                  []   \n",
       "..                             ...                 ...   \n",
       "190                             []                  []   \n",
       "191                 [trade unions]        [[135, 136]]   \n",
       "192                             []                  []   \n",
       "193                             []                  []   \n",
       "194                             []                  []   \n",
       "\n",
       "    total_words_organizations  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "..                        ...  \n",
       "190                         0  \n",
       "191                         2  \n",
       "192                         0  \n",
       "193                         0  \n",
       "194                         0  \n",
       "\n",
       "[195 rows x 33 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
